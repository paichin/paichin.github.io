---
title: 评论分析中有监督的关系对抽取
layout: post
categories: 'Machine Learning'
tags: ''
---
1. 问题回顾  
最近借阿里云一比赛的机会做了两个评论分析模型，原问题如下：    
![截图](https://paichin.github.io/assets/images4post/1.png)  
这里的一个核心问题就是修饰词和被修饰词的抽取，可以把它作为一个序列标注问题来解决。  


2. 模型和代码  
我分别用keras尝试了bilstm+crf和bert+crf两种方法。bert的f1线下大概做到0.8就没抽出时间再做了，而bilstm我只做到了0.7。代码先放在这里，后续发现更好的优化方式再继续学习。  
[完整代码](https://github.com/paichin/dl-models---analyse-des-commentaires/tree/master)  
  
3. 理论部分  
  简单介绍一下CRF（条件随机场）。《统计学习方法》中对条件随机场的定义：  
  ![截图](https://paichin.github.io/assets/images4post/2.png)  
  通俗理解大概是Y_v的条件概率只与与它有边相连的结点有关。定义中涉及到了无向图，那先来看一下有向图的定义：  <br>

  ![1567825276099](https://paichin.github.io/assets/images4post/3.png)

  不难理解，它们的联合概率可表示如下：
  $$
  P(x_1,...,x_n)=P(x_1)·P(x_2|x_1)·P(x_3|x_2)·P(x_4|x_2)·P(x_5|x_3,x_4)
  $$
  <br>贝叶斯网络就是有向的。

  <br>无向图一般就指马尔科夫网络：：<br>

  ![截图](https://paichin.github.io/assets/images4post/4.png)<br>

  在无向图G=(V,E)中，V表示节点，E表示边之间的依赖关系。

  可用因子分解P=(Y)将图的联合概率写为若干联合概率的乘积，具体的分法是将图分为若干个最大团。最大团的定义就是节点之间两两连通且不能加入任何一个新的节点使它成为一个更大的最大团。

  如上图的联合概率可写为：
  $$
  P(Y)=\frac{1}{Z(x)}(ψ_1(X_1,X_3,X_4)·ψ_1(X_2,X_3,X_4))
  $$
  <br>

  一般的形式为：<br>
  $$
  P(Y)=\frac{1}{Z(x)}\prod_{c}ψ_c(Y_c)
  $$
  <br>其中C为最大团，Z为归一化项，即：<br>
  $$
  Z(x)=\sum_y\prod_cψ_c(Y_c)
  $$
  <br>
  $$
  ψ_c(Y_c)
  $$
  称为势函数，要求为正，通常定义为指数函数：
  $$
  ψ_c(Y_c)=e^{-E(Y_c)}
  $$
  

4. 其中涉及到了。